---
title: "Assignment 04 — Lab 04 Machine Learning on Scale"
subtitle: "Causal and Predictive Analytics in Spark"
author:
  - name: "Othmane Elouardi"
    affiliations:
      - id: bu
        name: "Boston University"
        city: "Boston"
        state: "MA"
date: "2025-10-08"
number-sections: true
format:
  html:
    theme:
      light: lux
      dark: slate
    toc: true
    toc-depth: 3
    toc-location: right
    smooth-scroll: true
    code-fold: true
    code-tools: true
    code-line-numbers: true
    highlight-style: a11y
    page-layout: article
    css: styles.css
    grid:
      body-width: 900px
      margin-width: 280px
execute:
  echo: true
  warning: false
  error: false
  freeze: auto
jupyter: env
---


# Introduction
PySpark is applied to large-scale employment data from the Lightcast Job Postings dataset to develop and evaluate salary prediction models. The workflow involves engineering key features from structured columns, training a Linear Regression model, and assessing performance using RMSE and R² metrics. Visual diagnostic plots are generated to interpret model accuracy and residual patterns. The final analysis is documented, version-controlled, and submitted via GitHub, demonstrating end-to-end data processing and predictive modeling on a distributed computing platform.

# Load the Dataset
 **PySpark** is used to load the *Lightcast Job Postings* dataset into a Spark DataFrame.  
This approach enables us to efficiently handle large datasets within the EC2 environment before proceeding with feature engineering and regression analysis.

```{python}
# Load the Lightcast dataset with PySpark

from pyspark.sql import SparkSession
import os

# Initialize Spark session 
spark = (
    SparkSession.builder
    .appName("LightcastData")
    .config("spark.driver.memory", "1g")
    .getOrCreate()
)

# Define dataset path
csv_path = "data/lightcast_job_postings.csv"

# Check path validity
if not os.path.exists(csv_path):
    raise FileNotFoundError(f"❌ Could not find {csv_path}. Please ensure the file exists in the data/ folder.")

# Load dataset
df = (
    spark.read
    .option("header", "true")       # First row as headers
    .option("inferSchema", "true")  # Auto-detect data types
    .option("multiLine", "true")    # Handle multi-line text fields
    .option("escape", "\"")         # Handle embedded quotes
    .csv(csv_path)
)

# Confirm load success
print("✅ Dataset successfully loaded!")
df.printSchema()
df.show(5, truncate=False)
```



# Feature Engineering

Feature engineering is a crucial step in preparing the dataset for machine learning.  
This section cleans the data, encodes categorical variables, and constructs feature vectors for model training.

```{python}
# ======================================================
# FEATURE ENGINEERING
# ======================================================

from pyspark.sql import functions as F
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler

# ------------------------------------------------------
# 1. Drop rows with missing target or key features
# ------------------------------------------------------
df_clean = df.dropna(subset=[
    "SALARY", "MIN_YEARS_EXPERIENCE", "MAX_YEARS_EXPERIENCE",
    "EMPLOYMENT_TYPE_NAME", "STATE_NAME", "MIN_EDULEVELS_NAME"
])

print(f"✅ Rows after dropping nulls: {df_clean.count():,}")

# ------------------------------------------------------
# 2. Create new feature: MIN_YEARS_EXPERIENCE_SQ
# ------------------------------------------------------
df_clean = df_clean.withColumn(
    "MIN_YEARS_EXPERIENCE_SQ",
    F.pow(F.col("MIN_YEARS_EXPERIENCE"), 2)
)

# ------------------------------------------------------
# 3. Encode categorical variables
# ------------------------------------------------------
cat_cols = ["EMPLOYMENT_TYPE_NAME", "STATE_NAME", "MIN_EDULEVELS_NAME"]

indexers = [
    StringIndexer(inputCol=c, outputCol=f"{c}_IDX", handleInvalid="keep")
    for c in cat_cols
]

encoders = [
    OneHotEncoder(inputCol=f"{c}_IDX", outputCol=f"{c}_OHE")
    for c in cat_cols
]

# Apply indexers sequentially
for idx in indexers:
    df_clean = idx.fit(df_clean).transform(df_clean)

# Apply one-hot encoders sequentially
for enc in encoders:
    df_clean = enc.fit(df_clean).transform(df_clean)

# ------------------------------------------------------
# 4. Assemble final features
# ------------------------------------------------------
numeric_cols = [
    "MIN_YEARS_EXPERIENCE", 
    "MAX_YEARS_EXPERIENCE", 
    "MIN_YEARS_EXPERIENCE_SQ"
]

ohe_cols = [f"{c}_OHE" for c in cat_cols]

assembler = VectorAssembler(
    inputCols=numeric_cols + ohe_cols,
    outputCol="features"
)

df_fe = assembler.transform(df_clean)

# ------------------------------------------------------
# 5. Show sample of processed data
# ------------------------------------------------------
df_fe.select(
    "SALARY", "MIN_YEARS_EXPERIENCE", "STATE_NAME", "features"
).show(5, truncate=False)

```

# Train/Test Split

Splitting the data into training and testing sets ensures that the model is evaluated on unseen data, which helps measure its generalization performance.  
Here an **80/20 split** is used, a common practice that provides a large enough training set while reserving sufficient data for evaluation.

```{python}
# ======================================================
# TRAIN / TEST SPLIT
# ======================================================

# Perform random split with reproducibility
train_df, test_df = df_fe.randomSplit([0.8, 0.2], seed=42)

# Display record counts for each subset
train_count = train_df.count()
test_count = test_df.count()
total_count = df_fe.count()

print(f"✅ Total records: {total_count:,}")
print(f"🧠 Training set: {train_count:,} rows ({train_count/total_count:.1%})")
print(f"🧾 Testing set:  {test_count:,} rows ({test_count/total_count:.1%})")

```




# Linear Regression

Zero-variance features to restore full rank, train a Linear Regression model for
prediction, and assemble a coefficient table with **SE, t, p, 95% CI** using LR/GLR or a
bootstrap fallback when analytic standard errors are unavailable.

```{python}
# ======================================================
# LINEAR REGRESSION with robust & fast inference
#   - zero-variance pruning (Summarizer.variance)
#   - LR (L-BFGS + tiny ridge) metrics on test set
#   - LR -> GLR -> Bootstrap fallback for SE/t/p
# ======================================================

from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression
from pyspark.ml.feature import VectorSlicer
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.stat import Summarizer
from pyspark.sql import functions as F
import math, numpy as np

# ---- Speed / stability toggles ----
DO_BOOTSTRAP = False       # turn ON only if you really need SEs; this saves lots of time
B = 8                      # bootstrap iterations if enabled
BOOTSTRAP_FRACTION = 0.85  # subsample per bootstrap to speed up
RIDGE = 1e-4               # tiny L2 to avoid singularities
MAXITER_LR = 200
MAXITER_GLR = 120
TOL = 1e-5

# -----------------------------
# Helpers
# -----------------------------
def extract_feature_names(df, features_col="features"):
    """Read feature names from Vector metadata; fallback to generic names."""
    meta = df.schema[features_col].metadata
    try:
        attrs = meta["ml_attr"]["attrs"]
        names = []
        for typ in ("binary", "numeric"):
            if typ in attrs:
                for a in attrs[typ]:
                    names.append(a.get("name", f"f_{a.get('idx', len(names))}"))
        return names
    except Exception:
        size = df.selectExpr(f"size({features_col}) as n").head().n
        return [f"feature_{i}" for i in range(size)]

def normal_pvalue_from_t(t):
    """Two-sided p-value from z/t using normal approx."""
    if t is None or t != t:
        return float("nan")
    return 2.0 * (1.0 - 0.5 * (1 + math.erf(abs(float(t))/math.sqrt(2))))

def safe_ci(beta, se, z=1.96):
    try:
        if se is None or se != se:
            return float("nan"), float("nan")
        return float(beta - z*se), float(beta + z*se)
    except Exception:
        return float("nan"), float("nan")

def build_table(coefs, ses, names, intercept=None, intercept_se=float("nan")):
    # Align lengths
    if len(names) != len(coefs):
        if len(names) > len(coefs):
            names = names[:len(coefs)]
        else:
            names += [f"feature_{i}" for i in range(len(names), len(coefs))]

    rows = []
    for n, b, se in zip(names, coefs, ses):
        t = float("nan") if (se is None or se != se or se == 0.0) else float(b / se)
        p = normal_pvalue_from_t(t)
        lo, hi = safe_ci(b, se)
        rows.append((n, float(b), float(se) if se == se else float("nan"), t, p, lo, hi))

    coef_df = spark.createDataFrame(rows, ["feature", "coef", "se", "t", "p", "ci_lo", "ci_hi"])

    # Intercept row (if provided)
    if intercept is not None:
        t_i = float("nan") if (intercept_se != intercept_se or intercept_se == 0.0) else float(intercept / intercept_se)
        p_i = normal_pvalue_from_t(t_i)
        lo_i, hi_i = safe_ci(intercept, intercept_se)
        irow = spark.createDataFrame(
            [("Intercept", float(intercept), float(intercept_se), t_i, p_i, lo_i, hi_i)],
            ["feature", "coef", "se", "t", "p", "ci_lo", "ci_hi"]
        )
        coef_df = irow.unionByName(coef_df)

    return coef_df

# ---------------------------------------------
# 1) Zero-variance pruning on TRAIN (robust)
# ---------------------------------------------
feat_names_full = extract_feature_names(train_df, "features")

var_row = train_df.select(
    Summarizer.variance(train_df["features"]).alias("var")
).first()

# Convert variance vector to 1-D numpy safely
variances = var_row["var"].toArray() if hasattr(var_row["var"], "toArray") else np.array(var_row["var"]).ravel()

keep_idx = [int(i) for i, v in enumerate(variances) if (v is not None) and not np.isnan(v) and v > 1e-12]
if not keep_idx:  # safety fallback
    keep_idx = list(range(len(variances)))

removed = len(variances) - len(keep_idx)
print(f"ℹ️ Removed {removed} zero-variance feature(s)." if removed > 0 else "ℹ️ No zero-variance features found.")

slicer = VectorSlicer(inputCol="features", outputCol="features_nz", indices=keep_idx)
train_nz = slicer.transform(train_df).drop("features").withColumnRenamed("features_nz", "features")
test_nz  = slicer.transform(test_df ).drop("features").withColumnRenamed("features_nz", "features")

feat_names = [feat_names_full[i] for i in keep_idx] if keep_idx else feat_names_full

# Cache & materialize once to avoid recomputation across fits
train_nz = train_nz.repartition(4).cache()
test_nz  = test_nz.repartition(4).cache()
_ = train_nz.count(); _ = test_nz.count()

# ---------------------------------------------
# 2) Fit Linear Regression (fast/stable) + TEST metrics
# ---------------------------------------------
lr = LinearRegression(
    featuresCol="features",
    labelCol="SALARY",
    predictionCol="prediction",
    fitIntercept=True,
    regParam=RIDGE,             # tiny L2 prevents singularities
    elasticNetParam=0.0,
    solver="l-bfgs",            # faster & avoids Cholesky path
    maxIter=MAXITER_LR,
    tol=TOL,
    standardization=True
)
lr_model = lr.fit(train_nz)
lr_sum   = lr_model.summary

e_rmse = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="rmse")
e_r2   = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="r2")
e_mae  = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction", metricName="mae")

pred_test = lr_model.transform(test_nz).cache()
rmse_test = e_rmse.evaluate(pred_test)
r2_test   = e_r2.evaluate(pred_test)
mae_test  = e_mae.evaluate(pred_test)

print(f"✅ Test RMSE: {rmse_test:,.2f}")
print(f"✅ Test MAE : {mae_test:,.2f}")
print(f"✅ Test R²  : {r2_test:,.4f}")

print("\n--- Training Metrics (reference) ---")
print(f"RMSE: {lr_sum.rootMeanSquaredError:,.2f} | MAE: {lr_sum.meanAbsoluteError:,.2f} | R²: {lr_sum.r2:,.4f}")

# ---------------------------------------------
# 3) Inference: LR -> GLR -> Bootstrap fallback
# ---------------------------------------------
coef_df_out = None
got_inference = False

# (a) Try LR analytic inference (may be unavailable)
try:
    ses_lr   = list(lr_sum.coefficientStandardErrors)
    coefs_lr = list(lr_model.coefficients.toArray())
    coef_df_out = build_table(coefs_lr, ses_lr, feat_names, intercept=lr_model.intercept, intercept_se=float("nan"))
    got_inference = True
    print("ℹ️ Using LR analytic standard errors.")
except Exception:
    pass

# (b) GLR fallback (Gaussian/identity) with tiny ridge and L-BFGS
if not got_inference:
    try:
        glr = GeneralizedLinearRegression(
            featuresCol="features", labelCol="SALARY", predictionCol="prediction_glr",
            family="gaussian", link="identity",
            fitIntercept=True,
            regParam=RIDGE,
            maxIter=MAXITER_GLR,
            tol=TOL
        )
        glr_model = glr.fit(train_nz)
        glr_sum   = glr_model.summary

        ses_all = list(glr_sum.coefficientStandardErrors)  # may include intercept as last element
        coefs_g = list(glr_model.coefficients.toArray())

        # Intercept SE often appears as the last element
        intercept_se = float("nan")
        if len(ses_all) == len(coefs_g) + 1:
            intercept_se = float(ses_all[-1])
            ses_g = ses_all[:-1]
        else:
            ses_g = ses_all

        coef_df_out = build_table(coefs_g, ses_g, feat_names, intercept=glr_model.intercept, intercept_se=intercept_se)
        got_inference = True
        print("ℹ️ Using GLR analytic standard errors.")
    except Exception:
        pass

# (c) Bootstrap fallback (lightweight) if analytic SEs are unavailable
if not got_inference:
    if DO_BOOTSTRAP:
        print(f"⚠️ Analytic SE unavailable — running bootstrap (B={B}).")
        coef_mat = []
        for b in range(B):
            samp = train_nz.sample(withReplacement=True, fraction=BOOTSTRAP_FRACTION, seed=2025 + b)
            m = lr.fit(samp)
            coef_mat.append(m.coefficients.toArray())
        coef_mat = np.array(coef_mat)  # [B, p]
        coefs = lr_model.coefficients.toArray()
        ses   = np.std(coef_mat, axis=0, ddof=1)
        coef_df_out = build_table(list(coefs), list(ses), feat_names, intercept=lr_model.intercept, intercept_se=float("nan"))
        print("ℹ️ Bootstrap SE computed.")
    else:
        print("ℹ️ Skipping bootstrap; reporting coefficients without SE.")
        coefs = lr_model.coefficients.toArray()
        ses   = [float("nan")] * len(coefs)
        coef_df_out = build_table(list(coefs), ses, feat_names, intercept=lr_model.intercept, intercept_se=float("nan"))

# Order and display
coef_df_out = coef_df_out.withColumn("abs_t", F.abs(F.col("t"))).orderBy(F.desc_nulls_last("abs_t"))

print("\n--- Top 25 coefficients by |t| ---")
coef_df_out.select("feature", "coef", "se", "t", "p", "ci_lo", "ci_hi").show(25, truncate=False)

# save the full table
coef_df_out.coalesce(1).write.mode("overwrite").option("header", True).csv("output/linear_coef_table")

```



## Generalized Linear Regression Summary

```{python}
# ======================================================
# GLR SUMMARY (defensive, with bootstrap fallback)
# ======================================================

from pyspark.ml.regression import GeneralizedLinearRegression
from pyspark.sql import functions as F
import math, numpy as np

# ---------- safety: cache the pruned datasets ----------
try:
    train_nz = train_nz.cache(); test_nz = test_nz.cache()
    _ = train_nz.count(); _ = test_nz.count()
except NameError:
    # If you haven't run the train/test split + pruning cells yet
    raise RuntimeError("train_nz/test_nz not found. Run the Train/Test Split cell first.")

# ---------- settings (tweakable) ----------
DO_BOOTSTRAP = True
B = 8                    # keep modest for speed
BOOTSTRAP_FRACTION = 0.85
Z_95 = 1.96

# ---------- helpers ----------
def extract_feature_names(df, features_col="features"):
    meta = df.schema[features_col].metadata
    try:
        attrs = meta["ml_attr"]["attrs"]
        names = []
        for typ in ("binary", "numeric"):
            if typ in attrs:
                for a in attrs[typ]:
                    names.append(a.get("name", f"f_{a.get('idx', len(names))}"))
        return names
    except Exception:
        size = df.selectExpr(f"size({features_col}) as n").first().n
        return [f"feature_{i}" for i in range(size)]

def normal_pvalue_from_t(t):
    if t is None or (isinstance(t, float) and math.isnan(t)):
        return float("nan")
    z = abs(float(t))
    return 2.0 * (1.0 - 0.5 * (1 + math.erf(z / math.sqrt(2))))

def build_table(coefs, ses, names, intercept=None, intercept_se=float("nan")):
    # align lengths
    if len(names) != len(coefs):
        if len(names) > len(coefs):
            names = names[:len(coefs)]
        else:
            names += [f"feature_{i}" for i in range(len(names), len(coefs))]

    rows = []
    for n, b, se in zip(names, coefs, ses):
        if se is None or (isinstance(se, float) and math.isnan(se)) or se == 0.0:
            t = float("nan"); p = float("nan"); lo = float("nan"); hi = float("nan")
        else:
            t = float(b) / float(se)
            p = normal_pvalue_from_t(t)
            lo = float(b) - Z_95*float(se)
            hi = float(b) + Z_95*float(se)
        rows.append((n, float(b), float(se) if se == se else float("nan"), t, p, lo, hi))

    coef_df = spark.createDataFrame(rows, ["feature", "coef", "se", "t", "p", "ci_lo", "ci_hi"])

    # intercept row (optional)
    if intercept is not None:
        if (intercept_se is None) or (isinstance(intercept_se, float) and math.isnan(intercept_se)) or intercept_se == 0.0:
            t_i = float("nan"); p_i = float("nan"); lo_i = float("nan"); hi_i = float("nan")
        else:
            t_i = float(intercept) / float(intercept_se)
            p_i = normal_pvalue_from_t(t_i)
            lo_i = float(intercept) - Z_95*float(intercept_se)
            hi_i = float(intercept) + Z_95*float(intercept_se)
        irow = spark.createDataFrame(
            [("Intercept", float(intercept), float(intercept_se) if intercept_se==intercept_se else float("nan"),
              t_i, p_i, lo_i, hi_i)],
            ["feature", "coef", "se", "t", "p", "ci_lo", "ci_hi"]
        )
        coef_df = irow.unionByName(coef_df)

    return coef_df

# ---------- 1) Fit GLR and print model metrics (all getattr-guarded) ----------
glr = GeneralizedLinearRegression(
    featuresCol="features", labelCol="SALARY", predictionCol="prediction_glr",
    family="gaussian", link="identity", fitIntercept=True, regParam=0.0, maxIter=100
)
glr_model = glr.fit(train_nz)
glr_sum   = glr_model.summary

print("✅ GLR Model Summary")
print(f"AIC: {getattr(glr_sum, 'aic', float('nan')):.2f}")
print(f"Deviance: {getattr(glr_sum, 'deviance', float('nan')):.2f}")
print(f"Dispersion: {getattr(glr_sum, 'dispersion', float('nan')):.4f}")
print(f"Null Deviance: {getattr(glr_sum, 'nullDeviance', float('nan')):.2f}")
print(f"Residual DF: {getattr(glr_sum, 'residualDegreeOfFreedom', float('nan'))}")

feat_names = extract_feature_names(train_nz, "features")
coefs = list(glr_model.coefficients.toArray())

# ---------- 2) Try analytic SE; else bootstrap; else NA ----------
coef_df_glr = None
intercept_se = float("nan")

try:
    ses_all = list(glr_sum.coefficientStandardErrors)  # may include intercept as last element
    if len(ses_all) == len(coefs) + 1:
        intercept_se = float(ses_all[-1]); ses = ses_all[:-1]
    else:
        ses = ses_all
    coef_df_glr = build_table(coefs, ses, feat_names, intercept=glr_model.intercept, intercept_se=intercept_se)
    print("ℹ️ Using GLR analytic standard errors.")
except Exception:
    print("⚠️ GLR analytic SE unavailable.")
    if DO_BOOTSTRAP:
        print(f"⚠️ Running GLR bootstrap (B={B}).")
        coef_mat = []
        for b in range(B):
            samp = train_nz.sample(withReplacement=True, fraction=BOOTSTRAP_FRACTION, seed=4100 + b)
            m = glr.fit(samp)
            coef_mat.append(m.coefficients.toArray())
        coef_mat = np.array(coef_mat)
        ses_bs   = np.std(coef_mat, axis=0, ddof=1)
        coef_df_glr = build_table(coefs, list(ses_bs), feat_names, intercept=glr_model.intercept, intercept_se=float("nan"))
        print("ℹ️ Bootstrap SE computed.")
    else:
        # As a last resort, output coefficients with NA SE (still a valid table)
        coef_df_glr = build_table(coefs, [float("nan")]*len(coefs), feat_names, intercept=glr_model.intercept)

# ---------- 3) Order and show ----------
coef_df_glr = coef_df_glr.withColumn("abs_t", F.abs(F.col("t"))).orderBy(F.desc_nulls_last("abs_t"))
print("\n--- Top 25 GLR coefficients by |t| ---")
coef_df_glr.select("feature", "coef", "se", "t", "p", "ci_lo", "ci_hi").show(25, truncate=False)

# Optional: save
coef_df_glr.coalesce(1).write.mode("overwrite").option("header", True).csv("output/glr_coef_table")


```


### Interpretation

The Generalized Linear Regression model produced an AIC of approximately 71,000, and the dispersion parameter aligns well with the salary scale. According to bootstrap-based standard errors, employment type and education level have the most significant impact on salary. Specifically, full-time positions and advanced degrees, such as Master’s and Ph.D., considerably increase the predicted salary, while part-time roles and lower education levels lead to a decrease. Geographic factors also play an important role, highlighting the variations in labor markets at the state level. Overall, the model effectively identifies and interprets key relationships while ensuring numerical stability through bootstrapped inference.





# Random Forest Regressor

```{python}
# ======================================================
# RANDOM FOREST REGRESSOR 
#   - trains on train_nz, evaluates on test_nz
#   - robust feature-name handling for importances
#   - caches data to avoid recomputation
# ======================================================

from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.sql import functions as F

# ----------- Hyperparameters (edit here) -----------
NUM_TREES = 200        # 100–500 per instructions
MAX_DEPTH = 6          # 4–10 per instructions
FEATURE_SUBSET = "sqrt"
SUBSAMPLE = 0.8
MAX_BINS = 64
SEED = 42

# ----------- Safety: ensure train/test exist, cache once -----------
try:
    train_nz  # noqa: F401
    test_nz   # noqa: F401
except NameError:
    raise RuntimeError("train_nz/test_nz not found. Run the train/test split + feature steps first.")

# Cache & materialize to prevent long DAG recomputes
train_nz = train_nz.repartition(4).cache()
test_nz  = test_nz.repartition(4).cache()
_ = train_nz.count(); _ = test_nz.count()

# ----------- Helper: robust feature names -----------
def extract_feature_names(df, features_col="features"):
    meta = df.schema[features_col].metadata
    try:
        attrs = meta["ml_attr"]["attrs"]
        names = []
        for typ in ("binary", "numeric"):
            if typ in attrs:
                for a in attrs[typ]:
                    names.append(a.get("name", f"f_{a.get('idx', len(names))}"))
        return names
    except Exception:
        size = df.selectExpr(f"size({features_col}) as n").first().n
        return [f"feature_{i}" for i in range(size)]

feature_names = extract_feature_names(train_nz, "features")

# ----------- 1) Train RF -----------
rf = RandomForestRegressor(
    featuresCol="features",
    labelCol="SALARY",
    predictionCol="prediction_rf",
    numTrees=NUM_TREES,
    maxDepth=MAX_DEPTH,
    featureSubsetStrategy=FEATURE_SUBSET,
    subsamplingRate=SUBSAMPLE,
    minInstancesPerNode=2,
    maxBins=MAX_BINS,
    seed=SEED
)
rf_model = rf.fit(train_nz)

# ----------- 2) Evaluate on TEST -----------
pred_rf = rf_model.transform(test_nz).cache()
_ = pred_rf.count()  # materialize once

e_rmse = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction_rf", metricName="rmse")
e_mae  = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction_rf", metricName="mae")
e_r2   = RegressionEvaluator(labelCol="SALARY", predictionCol="prediction_rf", metricName="r2")

rmse_rf = e_rmse.evaluate(pred_rf)
mae_rf  = e_mae.evaluate(pred_rf)
r2_rf   = e_r2.evaluate(pred_rf)

print(f"🌲 RF Test RMSE: {rmse_rf:,.2f}")
print(f"🌲 RF Test MAE : {mae_rf:,.2f}")
print(f"🌲 RF Test R²  : {r2_rf:,.4f}")

# ----------- 3) Feature Importances (robust) -----------
imp_vec = rf_model.featureImportances  # SparseVector
# Convert to dense Python list aligned to the actual vector length
try:
    vec_len = pred_rf.selectExpr("size(features) as n").first().n
except Exception:
    vec_len = len(feature_names)

importances = [0.0] * vec_len
for idx, val in zip(imp_vec.indices, imp_vec.values):
    if idx < vec_len:
        importances[int(idx)] = float(val)

# Align names to the vector length
if len(feature_names) != vec_len:
    if len(feature_names) > vec_len:
        feature_names = feature_names[:vec_len]
    else:
        feature_names += [f"feature_{i}" for i in range(len(feature_names), vec_len)]

imp_rows = list(zip(feature_names, importances))
imp_df = spark.createDataFrame(imp_rows, ["feature", "rf_importance"]).orderBy(F.desc("rf_importance"))

print("\n--- Top 20 Random Forest feature importances ---")
imp_df.show(20, truncate=False)

# Optional: save importances
# imp_df.coalesce(1).write.mode("overwrite").option("header", True).csv("output/rf_feature_importances")
```

