{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Assignment 04 — Lightcast Job Market Analysis\"\n",
        "author:\n",
        "  - name: \"Othmane Elouardi\"\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: \"Boston University\"\n",
        "        city: \"Boston\"\n",
        "        state: \"MA\"\n",
        "date: 2025-10-08\n",
        "number-sections: true\n",
        "format:\n",
        "  html:\n",
        "    theme:\n",
        "      light: lux\n",
        "      dark: slate\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    toc-location: right\n",
        "    smooth-scroll: true\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "    code-line-numbers: true\n",
        "    highlight-style: a11y\n",
        "    page-layout: article\n",
        "    css: styles.css\n",
        "    grid:\n",
        "      body-width: 900px     \n",
        "      margin-width: 280px   \n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "  error: false\n",
        "  freeze: auto\n",
        "jupyter: env\n",
        "---\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This report analyzes job postings from the **Lightcast Job Market dataset**, exploring salary trends, employment types, skill demand, and more.  \n",
        "All visualizations are interactive, allowing you to hover and explore insights dynamically.\n",
        "\n",
        "---\n",
        "\n",
        "# Load the Dataset"
      ],
      "id": "aa1abf23"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: load-data\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path(\"data/lightcast_job_postings.csv\")\n",
        "\n",
        "# 1) File sanity check\n",
        "assert DATA_PATH.exists(), f\"CSV not found at {DATA_PATH.resolve()}\"\n",
        "\n",
        "# 2) Robust read (handles wide schema + mixed types)\n",
        "df = pd.read_csv(\n",
        "    DATA_PATH,\n",
        "    low_memory=False,        # avoid dtype guessing issues\n",
        "    parse_dates=False,       # we’ll parse dates explicitly later\n",
        "    dtype=str                # keep raw text first; coerce below\n",
        ")\n",
        "\n",
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(f\"Rows: {len(df):,}  |  Columns: {len(df.columns):,}\")\n",
        "\n",
        "# 3) Quick schema peek (first 12 columns to keep output tidy)\n",
        "preview_cols = list(df.columns[:12])\n",
        "display(df[preview_cols].head(5))\n",
        "\n",
        "# 4) Helpful normalized aliases (so later sections work even if column names vary a bit)\n",
        "#    Feel free to add more aliases if your CSV headers differ.\n",
        "ALIASES = {\n",
        "    \"EMPLOYMENT_TYPE_NAME\": [\"EMPLOYMENT_TYPE_NAME\", \"EMPLOYMENT_TYPE\", \"EMP_TYPE\"],\n",
        "    \"SALARY_FROM\":          [\"SALARY_FROM\", \"SAL_FROM\", \"MIN_SALARY\", \"SALARY_MIN\"],\n",
        "    \"SALARY_TO\":            [\"SALARY_TO\", \"SAL_TO\", \"MAX_SALARY\", \"SALARY_MAX\"],\n",
        "    \"INDUSTRY_NAME\":        [\"INDUSTRY_NAME\", \"NAICS2_NAME\", \"NAICS_NAME\"],\n",
        "    \"JOB_TITLE\":            [\"JOB_TITLE\", \"TITLE_NAME\", \"TITLE\"],\n",
        "    \"POSTED\":               [\"POSTED\", \"POSTED_DATE\", \"DATE_POSTED\"],\n",
        "    \"REMOTE_TYPE_NAME\":     [\"REMOTE_TYPE_NAME\", \"REMOTE_TYPE\", \"REMOTE\"],\n",
        "    \"SKILL_NAME\":           [\"SKILL_NAME\", \"SKILL\"]\n",
        "}\n",
        "\n",
        "def pick(existing: list[str], candidates: list[str]) -> str | None:\n",
        "    for c in candidates:\n",
        "        if c in existing:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "use = {k: pick(df.columns.tolist(), v) for k, v in ALIASES.items()}\n",
        "print(\"Resolved column names:\", use)\n",
        "\n",
        "# 5) Minimal cleaning: numbers/dates we’ll need later\n",
        "if use[\"SALARY_FROM\"]:\n",
        "    df[\"SALARY_FROM_NUM\"] = pd.to_numeric(df[use[\"SALARY_FROM\"]], errors=\"coerce\")\n",
        "if use[\"SALARY_TO\"]:\n",
        "    df[\"SALARY_TO_NUM\"] = pd.to_numeric(df[use[\"SALARY_TO\"]], errors=\"coerce\")\n",
        "if use[\"POSTED\"]:\n",
        "    df[\"POSTED_DATE\"] = pd.to_datetime(df[use[\"POSTED\"]], errors=\"coerce\", utc=True).dt.date\n",
        "\n",
        "# 6) Tiny health report\n",
        "health = {\n",
        "    \"non-null rows (any)\": int(df.dropna(how=\"all\").shape[0]),\n",
        "    \"with salary_from\": int(df[\"SALARY_FROM_NUM\"].notna().sum() if \"SALARY_FROM_NUM\" in df else 0),\n",
        "    \"with salary_to\": int(df[\"SALARY_TO_NUM\"].notna().sum() if \"SALARY_TO_NUM\" in df else 0),\n",
        "    \"with posted_date\": int(df[\"POSTED_DATE\"].notna().sum() if \"POSTED_DATE\" in df else 0),\n",
        "}\n",
        "health"
      ],
      "id": "load-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salary Distribution by Employment Type\n"
      ],
      "id": "4fd38b6e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: salary-by-employment-type\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# usable columns\n",
        "col_emp = use.get(\"EMPLOYMENT_TYPE_NAME\")\n",
        "col_sal = \"SALARY_FROM_NUM\" if \"SALARY_FROM_NUM\" in df else use.get(\"SALARY_FROM\")\n",
        "\n",
        "if col_emp and col_sal:\n",
        "    # Drop missing values for clean plotting\n",
        "    subset = df.dropna(subset=[col_emp, col_sal])\n",
        "    \n",
        "    # filter extreme outliers for clearer visualization\n",
        "    q_low, q_high = subset[col_sal].quantile([0.05, 0.95])\n",
        "    subset = subset[(subset[col_sal] >= q_low) & (subset[col_sal] <= q_high)]\n",
        "\n",
        "    # Create the boxplot\n",
        "    fig = px.box(\n",
        "        subset,\n",
        "        x=col_emp,\n",
        "        y=col_sal,\n",
        "        color=col_emp,\n",
        "        title=\"Salary Distribution by Employment Type\",\n",
        "        template=\"plotly_dark\",\n",
        "        color_discrete_sequence=px.colors.qualitative.Bold\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Employment Type\",\n",
        "        yaxis_title=\"Salary (From)\",\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        font=dict(family=\"Inter\", size=13),\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        margin=dict(t=60, l=60, r=40, b=60)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"❌ Required columns not found for salary distribution plot.\")"
      ],
      "id": "salary-by-employment-type",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "\n",
        "The box plot shows how salary levels vary across different employment types. Full-time positions generally have higher median salaries and a wider pay range, reflecting greater earning potential but also more variability.\n",
        "In contrast, part-time and contract roles exhibit lower median salaries with tighter ranges, suggesting more consistency but fewer high-paying opportunities.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Salary Distribution by Industry"
      ],
      "id": "5e7e47a2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: salary-by-industry\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Resolve column names dynamically (using your earlier `use` dict if present)\n",
        "col_ind = (use.get(\"INDUSTRY_NAME\") if \"use\" in locals() else\n",
        "           (\"INDUSTRY_NAME\" if \"INDUSTRY_NAME\" in df.columns else None))\n",
        "col_sal = (\"SALARY_FROM_NUM\" if \"SALARY_FROM_NUM\" in df.columns else\n",
        "           (use.get(\"SALARY_FROM\") if \"use\" in locals() else\n",
        "            (\"SALARY_FROM\" if \"SALARY_FROM\" in df.columns else None)))\n",
        "\n",
        "if col_ind and col_sal:\n",
        "    # Keep only rows with industry and salary\n",
        "    dfi = df.dropna(subset=[col_ind, col_sal]).copy()\n",
        "\n",
        "    # Pick top-N industries by posting volume to keep the chart readable\n",
        "    TOP_N = 10\n",
        "    top_inds = (dfi[col_ind]\n",
        "                .value_counts(dropna=False)\n",
        "                .nlargest(TOP_N)\n",
        "                .index)\n",
        "    dfi = dfi[dfi[col_ind].isin(top_inds)]\n",
        "\n",
        "    # Trim extreme outliers globally for clarity (5th–95th percentile)\n",
        "    ql, qh = dfi[col_sal].quantile([0.05, 0.95])\n",
        "    dfi = dfi[(dfi[col_sal] >= ql) & (dfi[col_sal] <= qh)]\n",
        "\n",
        "    # Order industries by median salary (descending)\n",
        "    medians = dfi.groupby(col_ind)[col_sal].median().sort_values(ascending=False)\n",
        "    category_order = medians.index.tolist()\n",
        "\n",
        "    # Box plot (clean + interactive)\n",
        "    fig = px.box(\n",
        "        dfi,\n",
        "        x=col_ind,\n",
        "        y=col_sal,\n",
        "        color=col_ind,\n",
        "        category_orders={col_ind: category_order},\n",
        "        title=\"Salary Distribution by Industry (Top 10 by Postings)\",\n",
        "        template=\"plotly_dark\",\n",
        "        color_discrete_sequence=px.colors.qualitative.Bold,\n",
        "        points=False  # hide raw points to keep it tidy\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Industry\",\n",
        "        yaxis_title=\"Salary (From)\",\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        font=dict(family=\"Inter\", size=13),\n",
        "        xaxis_tickangle=35,\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        margin=dict(t=60, l=60, r=40, b=80),\n",
        "        showlegend=False\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"❌ Required columns not found for industry salary plot.\")\n"
      ],
      "id": "salary-by-industry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: salary-by-industry-stats\n",
        "#| echo: false\n",
        "#| warning: false\n",
        "\n",
        "if col_ind and col_sal:\n",
        "    stats = (df.dropna(subset=[col_ind, col_sal])\n",
        "               .groupby(col_ind)[col_sal]\n",
        "               .agg(N=\"size\", mean=\"mean\", median=\"median\", p25=lambda s: s.quantile(0.25),\n",
        "                    p75=lambda s: s.quantile(0.75))\n",
        "               .sort_values(\"median\", ascending=False)\n",
        "               .head(10))\n",
        "\n",
        "    # Round for neatness\n",
        "    display(stats.round(0))\n"
      ],
      "id": "salary-by-industry-stats",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "\n",
        "The chart shows that salary levels vary notably across industries. The Information and Accommodation and Food Services sectors exhibit the highest median and upper-range salaries, suggesting strong compensation potential in these fields.\n",
        "Meanwhile, industries like Administrative Support and Retail Trade tend to offer lower median salaries, reflecting more standardized pay structures and fewer high-paying roles.\n",
        "\n",
        "\n",
        "# Job Posting Trends Over Time\n"
      ],
      "id": "69739cfb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: job-posting-trends\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Ensure date column exists and is parsed\n",
        "if \"POSTED\" in df.columns:\n",
        "    df[\"POSTED_DATE\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\n",
        "\n",
        "    # Aggregate daily counts\n",
        "    trend = (df.dropna(subset=[\"POSTED_DATE\"])\n",
        "               .groupby(\"POSTED_DATE\")\n",
        "               .size()\n",
        "               .reset_index(name=\"Job_Postings\"))\n",
        "\n",
        "    # Create line chart\n",
        "    fig = px.line(\n",
        "        trend,\n",
        "        x=\"POSTED_DATE\",\n",
        "        y=\"Job_Postings\",\n",
        "        title=\"Job Posting Trends Over Time\",\n",
        "        template=\"plotly_dark\",\n",
        "        color_discrete_sequence=[\"#37f3c0\"]\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Posted Date\",\n",
        "        yaxis_title=\"Number of Job Postings\",\n",
        "        font=dict(family=\"Inter\", size=13),\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        hovermode=\"x unified\",\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        margin=dict(t=60, l=60, r=40, b=80),\n",
        "    )\n",
        "\n",
        "    fig.update_traces(line=dict(width=2.5))\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"❌ 'POSTED' column not found.\")\n"
      ],
      "id": "job-posting-trends",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "\n",
        "The trend line reveals noticeable fluctuations in job posting activity, indicating that hiring demand changes frequently over time. Peaks suggest periods of intensified recruitment, possibly driven by seasonal hiring cycles or new project launches, while the dips represent slower hiring phases.\n",
        "Overall, the data highlights a dynamic job market with recurring surges in posting volume.\n",
        "\n",
        "\n",
        "# Top 10 Job Titles by Count\n"
      ],
      "id": "1db124d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: top-job-titles\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "if \"TITLE_NAME\" in df.columns:\n",
        "    # Count occurrences and select top 10\n",
        "    top_jobs = df[\"TITLE_NAME\"].value_counts().nlargest(10)\n",
        "\n",
        "    # Create bar chart\n",
        "    fig = px.bar(\n",
        "        x=top_jobs.index,\n",
        "        y=top_jobs.values,\n",
        "        title=\"Top 10 Job Titles by Count\",\n",
        "        text_auto=True,\n",
        "        color=top_jobs.values,\n",
        "        color_continuous_scale=\"tealgrn\",\n",
        "        template=\"plotly_dark\"\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Job Title\",\n",
        "        yaxis_title=\"Number of Postings\",\n",
        "        font=dict(family=\"Inter\", size=13),\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        xaxis_tickangle=40,\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        margin=dict(t=60, l=60, r=40, b=100)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"❌ 'TITLE_NAME' column not found in dataset.\")\n"
      ],
      "id": "top-job-titles",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "The chart shows that Data Analyst is by far the most frequently posted job title, indicating a high market demand for data-focused professionals. Other roles like Unclassified, Enterprise Architect, and Data Engineer also appear prominently, reflecting the growing need for both analytical and technical expertise in data-driven organizations.\n",
        "\n",
        "# Remote vs On-Site Job Postings\n"
      ],
      "id": "98c986b4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: remote-vs-onsite\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "if \"REMOTE_TYPE_NAME\" in df.columns:\n",
        "    remote_counts = df[\"REMOTE_TYPE_NAME\"].value_counts().reset_index()\n",
        "    remote_counts.columns = [\"Remote Type\", \"Count\"]\n",
        "\n",
        "    fig = px.pie(\n",
        "        remote_counts,\n",
        "        names=\"Remote Type\",\n",
        "        values=\"Count\",\n",
        "        title=\"Remote vs On-Site Job Postings\",\n",
        "        color_discrete_sequence=px.colors.qualitative.Pastel\n",
        "    )\n",
        "\n",
        "    fig.update_traces(textposition=\"inside\", textinfo=\"percent+label\")\n",
        "    fig.update_layout(\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        font=dict(family=\"Inter\", size=14),\n",
        "        showlegend=False,\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\"\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "else:\n",
        "    print(\"❌ 'REMOTE_TYPE_NAME' column not found in dataset.\")\n"
      ],
      "id": "remote-vs-onsite",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "The chart shows that a large majority of job postings do not specify a remote type, while around 17% explicitly offer remote positions. A smaller portion of listings are hybrid or partially remote, indicating that while remote work is available, most employers still emphasize on-site or unspecified work arrangements.\n",
        "\n",
        "\n",
        "# Skill Demand Analysis by Industry (Stacked Bar Chart)\n"
      ],
      "id": "51c75982"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: skill-demand-by-industry\n",
        "#| echo: true\n",
        "#| warning: false\n",
        "#| message: false\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import ast\n",
        "\n",
        "# --- 1) Robustly parse SKILLS_NAME into lists, then explode ---\n",
        "def to_list(value):\n",
        "    \"\"\"Convert SKILLS_NAME cells to a list of clean strings.\"\"\"\n",
        "    if pd.isna(value) or value == \"\":\n",
        "        return []\n",
        "    if isinstance(value, list):\n",
        "        return [str(v).strip() for v in value]\n",
        "    s = str(value).strip()\n",
        "\n",
        "    # If it looks like a Python list literal, parse safely\n",
        "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
        "        try:\n",
        "            parsed = ast.literal_eval(s)\n",
        "            return [str(v).strip() for v in parsed if str(v).strip()]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Fall back to common delimiters\n",
        "    for sep in [\"|\", \";\", \" / \", \"/\", \",\"]:\n",
        "        if sep in s:\n",
        "            return [t.strip() for t in s.split(sep) if t.strip()]\n",
        "\n",
        "    # Otherwise treat the whole thing as one skill\n",
        "    return [s]\n",
        "\n",
        "required = {\"NAICS2_NAME\", \"SKILLS_NAME\"}\n",
        "if required.issubset(df.columns):\n",
        "    skills = df.loc[:, [\"NAICS2_NAME\", \"SKILLS_NAME\"]].copy()\n",
        "    skills[\"SKILLS_NAME\"] = skills[\"SKILLS_NAME\"].apply(to_list)\n",
        "    skills = skills.explode(\"SKILLS_NAME\", ignore_index=True)\n",
        "    skills = skills[skills[\"SKILLS_NAME\"].notna() & (skills[\"SKILLS_NAME\"] != \"\")]\n",
        "    skills.rename(columns={\"NAICS2_NAME\": \"Industry\", \"SKILLS_NAME\": \"Skill\"}, inplace=True)\n",
        "\n",
        "    # --- 2) Limit to top skills & top industries (keeps chart readable) ---\n",
        "    TOP_SKILLS = 8\n",
        "    TOP_INDS   = 10\n",
        "    top_skills = skills[\"Skill\"].value_counts().head(TOP_SKILLS).index\n",
        "    top_inds   = skills[\"Industry\"].value_counts().head(TOP_INDS).index\n",
        "    skills_top = skills[skills[\"Skill\"].isin(top_skills) & skills[\"Industry\"].isin(top_inds)]\n",
        "\n",
        "    agg = (skills_top\n",
        "           .groupby([\"Industry\", \"Skill\"])\n",
        "           .size()\n",
        "           .reset_index(name=\"Count\"))\n",
        "\n",
        "    # --- 3) Horizontal stacked bar (better for long labels) ---\n",
        "    fig = px.bar(\n",
        "        agg,\n",
        "        x=\"Count\",\n",
        "        y=\"Industry\",\n",
        "        color=\"Skill\",\n",
        "        orientation=\"h\",\n",
        "        barmode=\"stack\",\n",
        "        title=\"Skill Demand by Industry (Top Skills & Industries)\",\n",
        "        color_discrete_sequence=px.colors.qualitative.Vivid\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        height=640,\n",
        "        font=dict(family=\"Inter\", size=13),\n",
        "        title_font=dict(size=20, family=\"Inter\", color=\"#1f6feb\"),\n",
        "        xaxis_title=\"Skill Count\",\n",
        "        yaxis_title=\"Industry\",\n",
        "        yaxis=dict(categoryorder=\"total ascending\"),\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        legend_title_text=\"Skill\",\n",
        "        margin=dict(l=10, r=10, t=60, b=10)\n",
        "    )\n",
        "    fig.show()\n",
        "else:\n",
        "    missing = required - set(df.columns)\n",
        "    print(f\"❌ Missing required columns: {sorted(missing)}\")\n"
      ],
      "id": "a8c6d803",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "\n",
        "The chart shows that professional, scientific, and technical services industries have the highest demand for skills, especially in communication, data analysis, and leadership.\n",
        "Across most industries, soft skills like communication and problem-solving appear as consistently essential, highlighting their broad value alongside technical expertise such as SQL and computer science.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Salary Analysis by ONET Occupation Type (Bubble Chart)"
      ],
      "id": "582b052c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Salary Analysis by Occupation (Bubble Chart) - robust ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Load once if df isn't already present\n",
        "if \"df\" not in globals():\n",
        "    df = pd.read_csv(Path(\"data/lightcast_job_postings.csv\"), low_memory=False)\n",
        "\n",
        "work = df.copy()\n",
        "\n",
        "# ---------- Salary normalization (annualize) ----------\n",
        "# Make numeric\n",
        "for c in [\"SALARY_FROM\", \"SALARY_TO\", \"SALARY\"]:\n",
        "    if c in work.columns:\n",
        "        work[c] = pd.to_numeric(work[c], errors=\"coerce\")\n",
        "\n",
        "# Helper: annualize by period\n",
        "def annualize(row):\n",
        "    # prefer bounds if present, else SALARY\n",
        "    base = np.nan\n",
        "    if pd.notna(row.get(\"SALARY_FROM\")) and pd.notna(row.get(\"SALARY_TO\")):\n",
        "        base = 0.5 * (row[\"SALARY_FROM\"] + row[\"SALARY_TO\"])\n",
        "    elif pd.notna(row.get(\"SALARY_FROM\")):\n",
        "        base = row[\"SALARY_FROM\"]\n",
        "    elif pd.notna(row.get(\"SALARY_TO\")):\n",
        "        base = row[\"SALARY_TO\"]\n",
        "    elif pd.notna(row.get(\"SALARY\")):\n",
        "        base = row[\"SALARY\"]\n",
        "\n",
        "    if pd.isna(base):\n",
        "        return np.nan\n",
        "\n",
        "    period = str(row.get(\"ORIGINAL_PAY_PERIOD\", \"\")).strip().upper()\n",
        "    if period == \"HOUR\":\n",
        "        return base * 2080            # 40h * 52w\n",
        "    elif period == \"DAY\":\n",
        "        return base * 260             # 5d * 52w\n",
        "    elif period == \"WEEK\":\n",
        "        return base * 52\n",
        "    elif period == \"MONTH\":\n",
        "        return base * 12\n",
        "    # assume already annual\n",
        "    return base\n",
        "\n",
        "# Compute annual salary\n",
        "work[\"SALARY_ANNUAL\"] = work.apply(annualize, axis=1)\n",
        "\n",
        "# Keep a wide annual band to avoid clipping true values\n",
        "work = work[work[\"SALARY_ANNUAL\"].between(15000, 500000, inclusive=\"both\")]\n",
        "\n",
        "# ---------- Pick a grouping column that has variety among salary rows ----------\n",
        "candidates = [\n",
        "    \"SOC_2021_4_NAME\", \"SOC_2021_3_NAME\", \"SOC_2021_2_NAME\",\n",
        "    \"ONET_2019_NAME\", \"ONET_NAME\",\n",
        "    \"TITLE_NAME\"  # final fallback if none of the above has variety\n",
        "]\n",
        "\n",
        "def pick_group_col(frame, cols, min_unique=6):\n",
        "    avail = []\n",
        "    for c in cols:\n",
        "        if c in frame.columns:\n",
        "            n = frame[c].dropna().nunique()\n",
        "            avail.append((c, n))\n",
        "    # sort by original order but filter by variety\n",
        "    for c, n in avail:\n",
        "        if n >= min_unique:\n",
        "            return c, avail\n",
        "    # otherwise take the one with max variety among the available\n",
        "    if avail:\n",
        "        return max(avail, key=lambda x: x[1])[0], avail\n",
        "    return None, []\n",
        "\n",
        "group_col, availability = pick_group_col(work.dropna(subset=[\"SALARY_ANNUAL\"]), candidates)\n",
        "\n",
        "print(\"Grouping candidates (non-null uniques among rows with salary):\")\n",
        "for c, n in availability:\n",
        "    print(f\"  - {c}: {n}\")\n",
        "\n",
        "if not group_col:\n",
        "    print(\"❌ No suitable occupation/title column found.\")\n",
        "else:\n",
        "    print(f\"✅ Using group column: {group_col}\")\n",
        "\n",
        "    # ---------- Aggregate ----------\n",
        "    salary_df = (\n",
        "        work.dropna(subset=[group_col, \"SALARY_ANNUAL\"])\n",
        "            .groupby(group_col, as_index=False)\n",
        "            .agg(\n",
        "                Median_Salary=(\"SALARY_ANNUAL\", \"median\"),\n",
        "                Job_Postings=(group_col, \"size\")\n",
        "            )\n",
        "            .sort_values(\"Job_Postings\", ascending=False)\n",
        "    )\n",
        "\n",
        "    # If there are still tons of unique groups, keep the busiest N\n",
        "    top_n = 20\n",
        "    if len(salary_df) > top_n:\n",
        "        salary_df = salary_df.head(top_n)\n",
        "\n",
        "    # If everything collapsed to 1, show a short sample so you can sanity check\n",
        "    if salary_df[group_col].nunique() <= 1:\n",
        "        print(\"ℹ️ Still only one group after cleaning. Here are the top 10 rows with salary:\")\n",
        "        print(work.loc[work[\"SALARY_ANNUAL\"].notna(), [group_col, \"TITLE_NAME\", \"SALARY_ANNUAL\", \"ORIGINAL_PAY_PERIOD\"]].head(10))\n",
        "\n",
        "    # ---------- Plot ----------\n",
        "    fig = px.scatter(\n",
        "        salary_df,\n",
        "        x=group_col,\n",
        "        y=\"Median_Salary\",\n",
        "        size=\"Job_Postings\",\n",
        "        color=\"Median_Salary\",\n",
        "        size_max=42,\n",
        "        color_continuous_scale=\"Viridis\",\n",
        "        title=\"Salary Analysis by Occupation\",\n",
        "        hover_data={group_col: True, \"Median_Salary\": \":,.0f\", \"Job_Postings\": True}\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        xaxis_title=\"Occupation / Title\",\n",
        "        yaxis_title=\"Median Salary ($, annualized)\",\n",
        "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "        font=dict(family=\"Inter, 'Fira Sans', Arial\", size=13),\n",
        "        height=620\n",
        "    )\n",
        "    fig.update_xaxes(tickangle=35, tickfont=dict(size=11))\n",
        "\n",
        "    fig.show()\n"
      ],
      "id": "0491a7bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "\n",
        "This chart shows how median annualized salaries vary across the most common job titles in the dataset.\n",
        "Larger bubbles represent job titles with a higher number of postings, while color indicates the relative salary level.\n",
        "From the visualization, we can see that technical and leadership roles such as “Data Architects,” “Principal Data Engineers,” and “SAP Data Analytics Managers” tend to offer the highest median salaries (often exceeding $160K), while more common positions like “Data Analyst” or “Business Intelligence Analyst” have lower median pay but significantly higher posting volume, reflecting strong demand for analytical talent across industries.\n",
        "\n",
        "\n",
        "# Career Pathway Trends (Sankey Diagram)"
      ],
      "id": "7ec5da49"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Career Pathway Trends (Sankey): TITLE_NAME → ONET_NAME ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "REQ = {\"TITLE_NAME\", \"ONET_NAME\"}\n",
        "if not REQ.issubset(df.columns):\n",
        "    print(f\"❌ Missing columns for Sankey: need {REQ}, have {set(df.columns)}\")\n",
        "else:\n",
        "    # Params you can tweak\n",
        "    TOP_TITLES = 20      # keep top-N job titles by postings\n",
        "    TOP_ONETS  = 20      # keep top-N ONET occupations by postings\n",
        "    MIN_FLOW   = 10      # drop very tiny flows to declutter\n",
        "\n",
        "    # Clean & filter\n",
        "    sankey_df = (\n",
        "        df[[\"TITLE_NAME\", \"ONET_NAME\"]]\n",
        "        .dropna()\n",
        "        .assign(\n",
        "            TITLE_NAME=lambda d: d[\"TITLE_NAME\"].str.strip(),\n",
        "            ONET_NAME=lambda d: d[\"ONET_NAME\"].str.strip(),\n",
        "        )\n",
        "        .query(\"TITLE_NAME != '' and ONET_NAME != ''\")\n",
        "    )\n",
        "\n",
        "    # Keep only top titles / onets to make the diagram readable\n",
        "    top_titles = sankey_df[\"TITLE_NAME\"].value_counts().nlargest(TOP_TITLES).index\n",
        "    top_onets  = sankey_df[\"ONET_NAME\"].value_counts().nlargest(TOP_ONETS).index\n",
        "    sankey_df  = sankey_df[sankey_df[\"TITLE_NAME\"].isin(top_titles) & sankey_df[\"ONET_NAME\"].isin(top_onets)]\n",
        "\n",
        "    flows = (\n",
        "        sankey_df\n",
        "        .value_counts([\"TITLE_NAME\", \"ONET_NAME\"])\n",
        "        .rename(\"count\")\n",
        "        .reset_index()\n",
        "    )\n",
        "    flows = flows[flows[\"count\"] >= MIN_FLOW].sort_values(\"count\", ascending=False)\n",
        "\n",
        "    # Diagnostics\n",
        "    diag = {\n",
        "        \"Rows considered\": int(len(sankey_df)),\n",
        "        \"Unique Titles\": int(sankey_df[\"TITLE_NAME\"].nunique()),\n",
        "        \"Unique ONETs\": int(sankey_df[\"ONET_NAME\"].nunique()),\n",
        "        \"Flows kept\": int(len(flows)),\n",
        "        \"Min flow shown\": int(MIN_FLOW),\n",
        "    }\n",
        "    print(\"ℹ️ Sankey diagnostics:\", diag)\n",
        "\n",
        "    if flows.empty:\n",
        "        print(\"⚠️ No flows after filtering. Try lowering MIN_FLOW or increasing TOP_TITLES/TOP_ONETS.\")\n",
        "    else:\n",
        "        # Build node list\n",
        "        src_labels = flows[\"TITLE_NAME\"].tolist()\n",
        "        tgt_labels = flows[\"ONET_NAME\"].tolist()\n",
        "        all_labels = pd.Index(src_labels + tgt_labels).unique().tolist()\n",
        "\n",
        "        # indices for plotly\n",
        "        label_to_idx = {lab: i for i, lab in enumerate(all_labels)}\n",
        "        sources = flows[\"TITLE_NAME\"].map(label_to_idx).tolist()\n",
        "        targets = flows[\"ONET_NAME\"].map(label_to_idx).tolist()\n",
        "        values  = flows[\"count\"].tolist()\n",
        "\n",
        "        # Optional: color nodes by side (titles vs onets)\n",
        "        node_colors = []\n",
        "        for lab in all_labels:\n",
        "            if lab in top_titles:\n",
        "                node_colors.append(\"rgba(56, 182, 255, 0.8)\")  # blue-ish for titles\n",
        "            else:\n",
        "                node_colors.append(\"rgba(72, 201, 176, 0.8)\")  # teal-ish for ONET\n",
        "\n",
        "        link_color = \"rgba(200, 200, 200, 0.35)\"\n",
        "\n",
        "        fig = go.Figure(data=[go.Sankey(\n",
        "            arrangement=\"snap\",\n",
        "            node=dict(\n",
        "                pad=16,\n",
        "                thickness=18,\n",
        "                line=dict(width=0.5, color=\"rgba(0,0,0,0.25)\"),\n",
        "                label=all_labels,\n",
        "                color=node_colors\n",
        "            ),\n",
        "            link=dict(\n",
        "                source=sources,\n",
        "                target=targets,\n",
        "                value=values,\n",
        "                color=link_color\n",
        "            )\n",
        "        )])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"Career Pathway Trends (Job Title → ONET Occupation)\",\n",
        "            font=dict(size=12),\n",
        "            height=650,\n",
        "            margin=dict(l=10, r=10, t=50, b=10),\n",
        "            paper_bgcolor=\"rgba(0,0,0,0)\",\n",
        "            plot_bgcolor=\"rgba(0,0,0,0)\"\n",
        "        )\n",
        "        fig.show()\n"
      ],
      "id": "1b9260f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✏️ Explanation\n",
        "The Sankey diagram shows how various job titles—such as Data Analyst, Data Modeler, and ERP Business Analyst—flow into a single ONET occupation category, Business Intelligence Analysts.\n",
        "This highlights that many data-related positions ultimately map to the same occupational classification, reflecting the overlap and convergence of skills within business intelligence and analytics roles."
      ],
      "id": "c156fc4a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "env",
      "language": "python",
      "display_name": "Python (env)",
      "path": "/home/ubuntu/.local/share/jupyter/kernels/env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}